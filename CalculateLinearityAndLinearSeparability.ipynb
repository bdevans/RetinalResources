{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "colab_type": "text",
    "id": "kR-4eNdK6lYS",
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "# Code for calculating and plotting linearity and linear separability\n",
    "\n",
    "\n",
    "### Note-We have recently changed the layer convention such that  (Image, bipolar, ganglion, VVS 1-4) are (0, 2, 3, 4-7). I believe that I have updated this code in alignment with convention, but I haven't yet been able to test it. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "JLpLa8Jt7Vu4",
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# These are all the modules we'll be using later. \n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "#from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import scipy.linalg\n",
    "import scipy.stats\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "from six.moves import cPickle as pickle\n",
    "\n",
    "import sklearn\n",
    "import sklearn.linear_model\n",
    "\n",
    "sys.stdout.flush()\n",
    "\n",
    "#my_marker_size = 20;\n",
    "font = {'family' : 'normal',\n",
    "        'weight' : 'normal',\n",
    "        'size'   : 18}\n",
    "\n",
    "plt.rc('font', **font)\n",
    "plt.rcParams['lines.markersize'] = 8;\n",
    "#plt.tight_layout()\n",
    "\n",
    "\n",
    "params = {'legend.fontsize': 'x-large',\n",
    "          'figure.figsize': (15, 5),\n",
    "         'axes.labelsize': 'x-large',\n",
    "         'axes.titlesize':'x-large',\n",
    "         'xtick.labelsize':'x-large',\n",
    "         'ytick.labelsize':'x-large'}\n",
    "plt.rcParams.update(params)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Helper method to ensure that a directory exists\n",
    "def ensure_dir(file_path):\n",
    "    directory = os.path.dirname(file_path)\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "#Another helper method so I don't need to write if statements everywhere\n",
    "def verbose_print(verbose, str_to_print):\n",
    "    if(verbose):\n",
    "        print(str_to_print)\n",
    "        sys.stdout.flush()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "# Subroutines for running and computing activations\n",
    "------------\n",
    "\n",
    "#### We use a scheme where we pickle activations once and then load them for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desktop_path = os.path.join(os.path.join(os.path.expanduser('~')), 'Desktop/') \n",
    "pickle_dir = '/hdd/ActivationPickleHoard/' \n",
    "\n",
    "print('Pickle Dir is ' + pickle_dir)\n",
    "model_input_path = 'saved_models/'\n",
    "\n",
    "\n",
    "def big_pickle_dump(data, file_path, should_replace = True): #Workaround for pickle bug that I found on stackexchange\n",
    "    if(should_replace):\n",
    "        if(os.path.exists(file_path)):\n",
    "            os.remove(file_path);\n",
    "    \n",
    "    if(1):\n",
    "#        pickle.dump(data, open(file_path, 'wb'), encoding = 'latin1')        \n",
    "        pickle.dump(data, open(file_path, 'wb'))                \n",
    "#        pickle.dump(data, open(file_path, 'wb'), encoding = 'latin1')        \n",
    "#        pickle.dump(data, open(file_path, 'wb'), protocol=4)\n",
    "    else:\n",
    "        n_bytes = 2**31\n",
    "        max_bytes = 2**31 - 1\n",
    "    #    data = bytearray(n_bytes)\n",
    "        ## write\n",
    "        bytes_out = pickle.dumps(data)\n",
    "        with open(file_path, 'wb') as f_out:\n",
    "            for idx in range(0, len(bytes_out), max_bytes):\n",
    "                f_out.write(bytes_out[idx:idx+max_bytes])\n",
    "    \n",
    "def big_pickle_load(file_path): #Workaround for pickle bug that I found on stackexchange\n",
    "    return pickle.load(open(file_path, 'rb'), encoding= 'latin1')\n",
    "\n",
    "\n",
    "\n",
    "def ensure_batch_files_exist(model_name, layer, path = pickle_dir, batch_size = 200, full_size = 10000, verbose = True):\n",
    "    cur_layer_activations_list = [];\n",
    "    batch_start_list = list(range(0, full_size, batch_size))    \n",
    "    \n",
    "    for batch_start in batch_start_list:   \n",
    "        batch_pickle_path = batch_pickle_file_name(model_name, layer, batch_start, path)     \n",
    "        if(not os.path.exists(batch_pickle_path)):\n",
    "            print('Warning, ' + batch_pickle_path + ' doesnt exist!')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def load_layer_activations_from_batch_files(model_name, layer, path = pickle_dir, batch_size = 200, full_size = 10000, verbose = True):\n",
    "    cur_layer_activations_list = [];\n",
    "    batch_start_list = list(range(0, full_size, batch_size))\n",
    "    \n",
    "    for batch_start in batch_start_list:   \n",
    "        batch_pickle_path = batch_pickle_file_name(model_name, layer, batch_start, path)     \n",
    "        if(verbose):\n",
    "            print('Loading ' + batch_pickle_path)\n",
    "        cur_layer_batch_activations = big_pickle_load(batch_pickle_path);\n",
    "#            cur_layer_batch_activations = pickle.load(open(batch_pickle_path, 'rb'))\n",
    "\n",
    "        if(verbose):\n",
    "            print('Appending Shape of ' + str(np.shape(cur_layer_batch_activations)))\n",
    "        cur_layer_activations_list.append(cur_layer_batch_activations)\n",
    "\n",
    "    cur_layer_activations_array = np.array(cur_layer_activations_list)\n",
    "    act_array_shape = np.shape(cur_layer_activations_array);\n",
    "    if(verbose):    \n",
    "        print('Old Shape is ' + str(act_array_shape))\n",
    "    new_shape = tuple([full_size] +  list(act_array_shape[2:]));\n",
    "    if(verbose):    \n",
    "        #Reshapes so the (nbatch, batchsize, layer_shape ) goes to (nbatch* batchsize, layer_shape )\n",
    "        print('Reshaping ' + str(act_array_shape) + 'to' + str(new_shape))\n",
    "    reshaped_layer_activations = cur_layer_activations_array.reshape(new_shape)\n",
    "    return reshaped_layer_activations\n",
    "\n",
    "\n",
    "\n",
    "def load_layer_activations(model_name, layer, path = pickle_dir):\n",
    "    file_name_to_load = layer_pickle_file_name(model_name, layer, path);\n",
    "    return big_pickle_load(file_name_to_load);\n",
    "\n",
    "\n",
    "def batch_pickle_file_name(model_name, layer, batch, path):\n",
    "    return path + \"BatchActs_\"+ model_name + \"_layer\" + \"{:02}\".format(layer) + '_batch' + \"{:05}\".format(batch) + '.p'    \n",
    "\n",
    "\n",
    "def layer_pickle_file_name(model_name, layer,  path):\n",
    "    return path + \"FullActs_\"+ model_name + \"_layer\" + \"{:02}\".format(layer) +'.p'    \n",
    "\n",
    "\n",
    "\n",
    "def output_activations_to_pickle(model, input_data, layers_to_keep, model_name, output_dir = pickle_dir, verbose = True, batch_size = 200, full_size = 10000, make_batches = False, compile_batches = False, delete_batches_when_done = False, conditional_make_batches = True):\n",
    "    inp = model.input # input placeholder\n",
    "\n",
    "    out = [model.layers[layer_nb].output for layer_nb in layers_to_keep] # layer output\n",
    "    func = K.function([inp, K.learning_phase()], out) # function relating input to output\n",
    "\n",
    "    \n",
    "    batch_start_list = list(range(0, full_size, batch_size))\n",
    "    \n",
    "    if(make_batches):\n",
    "        #We make a bunch of individual pickle fils. Every (model, layer, batch) combination will have its own pickle file.     \n",
    "        for batch_start in batch_start_list:   \n",
    "            if(verbose):\n",
    "                print('Doing batch', batch_start)\n",
    "            output = func([input_data[batch_start:(batch_start+batch_size)], 0])  #  apply function to a particular input    \n",
    "            for (i_layer, layer) in enumerate(layers_to_keep):\n",
    "                batch_pickle_path = batch_pickle_file_name(model_name, layer, batch_start, output_dir)   \n",
    "                if(os.path.exists(batch_pickle_path) and conditional_make_batches):\n",
    "                    print('Path Already exists, deleting before making again');\n",
    "                    os.remove(batch_pickle_path)\n",
    "#                    return;\n",
    "                if(verbose):\n",
    "                    print('Dumping to ' + batch_pickle_path)\n",
    "                big_pickle_dump(output[i_layer], batch_pickle_path);\n",
    "\n",
    "        out = [model.layers[layer_nb].output for layer_nb in layers_to_keep] # layer output\n",
    "        func = K.function([inp, K.learning_phase()], out) # function relating input to output\n",
    "\n",
    "    if(compile_batches):\n",
    "        batch_start_list = list(range(0, full_size, batch_size))\n",
    "        #We make a bunch of individual pickle fils. Every (model, layer, batch) combination will have its own pickle file.     \n",
    "        for (i_layer, layer) in enumerate(layers_to_keep):\n",
    "            print('Assembling Layer', layer) \n",
    "            cur_layer_activations_list = [];\n",
    "            for batch_start in batch_start_list:   \n",
    "                batch_pickle_path = batch_pickle_file_name(model_name, layer, batch_start, output_dir)      \n",
    "                cur_layer_batch_activations = big_pickle_load(batch_pickle_path);\n",
    "    #            cur_layer_batch_activations = pickle.load(open(batch_pickle_path, 'rb'))\n",
    "                print('Appending Shape of ' + str(np.shape(cur_layer_batch_activations)))\n",
    "                cur_layer_activations_list.append(cur_layer_batch_activations)\n",
    "\n",
    "                #print(np.shape(cur_layer_batch_activations))\n",
    "                if(delete_batches_when_done):\n",
    "                    os.remove(batch_pickle_path)\n",
    "\n",
    "            cur_layer_activations_array = np.array(cur_layer_activations_list)\n",
    "            act_array_shape = np.shape(cur_layer_activations_array);\n",
    "            print('Old Shape is ' + str(act_array_shape))\n",
    "            new_shape = tuple([full_size] +  list(act_array_shape[2:]));\n",
    "            #Reshapes so the (nbatch, batchsize, layer_shape ) goes to (nbatch* batchsize, layer_shape )\n",
    "            print('Reshaping ' + str(act_array_shape) + 'to' + str(new_shape))\n",
    "            reshaped_layer_activations = cur_layer_activations_array.reshape(new_shape)\n",
    "    #        print(reshaped_layer_activations)\n",
    "            layer_pickle_path = layer_pickle_file_name(model_name, layer, output_dir)\n",
    "            if(verbose):\n",
    "                print('Old shape' + str(act_array_shape))\n",
    "                print('New Shape' + str(new_shape))\n",
    "                print('Dumping to ' + layer_pickle_path)\n",
    "                print('Reshaped_layer_activations shape' + str(np.shape(reshaped_layer_activations)))\n",
    "\n",
    "            big_pickle_dump(reshaped_layer_activations, layer_pickle_path);\n",
    "    #        pickle.dump(reshaped_layer_activations, open(layer_pickle_path, 'wb'))\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subroutines for calculating linear fits and separabilty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "   \n",
    "def isconv_channels_pixels(input_array):\n",
    "    if(len(np.shape(input_array)) == 4):\n",
    "        return (True, np.shape(input_array)[3], np.shape(input_array)[1] * np.shape(input_array)[2] )\n",
    "    else:\n",
    "        return (False, np.shape(input_array)[1], 1)\n",
    "\n",
    "\n",
    "        \n",
    "def possibly_ravel(data_to_fit):\n",
    "    # A helper method-The multitaskcv is slower than lassocv when the dimesnion = 1,\n",
    "    # so I'm adding this to speed things along when we just have to fit a 1D value\n",
    "    if(np.ndim(data_to_fit) == 1 or (np.ndim(data_to_fit) ==2 and np.shape(data_to_fit)[1] == 1)):\n",
    "        return data_to_fit.ravel();\n",
    "    else:\n",
    "        return data_to_fit;\n",
    "\n",
    "    \n",
    "    \n",
    "def possibly_multitask_lasso_cv(data_to_fit):\n",
    "    # A helper method-The multitaskcv is slower than lassocv when the dimesnion = 1,\n",
    "    # so I'm adding this to speed things along when we just have to fit a 1D value\n",
    "    if(np.ndim(data_to_fit) == 1 or (np.ndim(data_to_fit) ==2 and np.shape(data_to_fit)[1] == 1)):\n",
    "        return sklearn.linear_model.LassoCV();\n",
    "    else:\n",
    "        return sklearn.linear_model.MultiTaskLassoCV()\n",
    "\n",
    "        \n",
    "def one_way_multi_channel_ridge_var_exp(act_1, act_2, pixel_loc = 15, verbose = True, frac_for_training = .8):\n",
    "    verbose_print(verbose, 'Reshaping')\n",
    "    \n",
    "    n_data = np.shape(act_2)[0];\n",
    "    n_training = np.int(n_data * frac_for_training)\n",
    "\n",
    "    #Slices X(Act1) into training and test\n",
    "    reshaped_act1_x = act_1.reshape((np.shape(act_1)[0], np.prod(np.shape(act_1)[1:])))    \n",
    "    act1_x_train = reshaped_act1_x[:n_training, :]\n",
    "    act1_x_test = reshaped_act1_x[n_training:, :]\n",
    "\n",
    "    #Slices Y(Act2) into training and test\n",
    "    verbose_print(verbose, 'Original shapes are '+ str((np.shape(act_1), np.shape(act_2)) ) )\n",
    "    if(np.ndim(act_2) > 2):\n",
    "        cropped_act2 = act_2[:, pixel_loc, pixel_loc, :];        \n",
    "        notes_to_return = 'Took center pixel'\n",
    "    else:\n",
    "        pix_val_to_use = np.int(np.shape(act_2)[1]/2)\n",
    "        cropped_act2 = act_2[:, [pix_val_to_use, pix_val_to_use+1]]\n",
    "        notes_to_return = 'Warning, trying to predict a nonconvolutional layer, just took the medium two entries to predict'\n",
    "        verbose_print(verbose, notes_to_return)\n",
    "    reshaped_act2_y = cropped_act2.reshape((np.shape(cropped_act2)[0], np.prod(np.shape(cropped_act2)[1:])))\n",
    "    reshaped_act2_y_train = reshaped_act2_y[:n_training, :]    \n",
    "    act2_y_train = reshaped_act2_y[:n_training, :]\n",
    "    act2_y_test = reshaped_act2_y[n_training:, :]\n",
    "\n",
    "    est_12 = sklearn.linear_model.RidgeCV();\n",
    "    verbose_print(verbose, 'Training Est12 ' + str(type(est_12)) +  ' with shapes of ' + str(np.shape(reshaped_act1_x)) + ', ' + str(np.shape(reshaped_act2_y)));\n",
    "    est_12.fit(act1_x_train,  act2_y_train); \n",
    "    est_12_frac_var_exp = est_12.score(act1_x_test,  act2_y_test)\n",
    "    predict_act2_y_test = est_12.predict(act1_x_test)\n",
    "    verbose_print(verbose, 'Finished!')\n",
    "    \n",
    "    return_dict =  {'frac_var_exp': est_12_frac_var_exp, 'estimator': est_12, 'Y_real_vs_fit': (act2_y_test, predict_act2_y_test)}    \n",
    "    return_dict['Notes'] = notes_to_return\n",
    "    \n",
    "    \n",
    "    chan_wise_scores = [];\n",
    "    for chan in range(np.shape(act2_y_test)[1]):     \n",
    "        cur_chan_wise_score = np.corrcoef(act2_y_test[:, chan], predict_act2_y_test[:, chan])[1,0]\n",
    "        chan_wise_scores.append(cur_chan_wise_score)\n",
    "        \n",
    "        #This is true as N-> infinity. Figure if its true for small biases\n",
    "    return_dict['chan_wise_scores'] = chan_wise_scores\n",
    "    \n",
    "    return return_dict  \n",
    "#    return (est_21_frac_var_exp * act1_y_var, act1_y_var, est_12_frac_var_exp * act2_y_var, act2_y_var, est_21, est_12)\n",
    "    \n",
    "    \n",
    "def multi_channel_lasso_var_exp(act1, act2, pixel_loc = 15, verbose = True):\n",
    "    verbose_print(verbose, 'Reshaping')\n",
    "    reshaped_act1_x = act_1.reshape((np.shape(act_1)[0], np.prod(np.shape(act_1)[1:])))\n",
    "    reshaped_act2_x = act_2.reshape((np.shape(act_2)[0], np.prod(np.shape(act_2)[1:])))\n",
    "\n",
    "    cropped_act1 = act1[:, pixel_loc, pixel_loc, :];\n",
    "    cropped_act2 = act2[:, pixel_loc, pixel_loc, :];\n",
    "    \n",
    "    reshaped_act1_y = cropped_act1.reshape((np.shape(cropped_act1)[0], np.prod(np.shape(cropped_act1)[1:])))\n",
    "    act1_y_var = np.sum(np.var(reshaped_act1_y, axis = 0));    \n",
    "    verbose_print(verbose, 'Var1 is ' + str(act1_y_var))\n",
    "    reshaped_act1_y = possibly_ravel(reshaped_act1_y)\n",
    "    \n",
    "    reshaped_act2_y = cropped_act2.reshape((np.shape(cropped_act2)[0], np.prod(np.shape(cropped_act2)[1:])))\n",
    "    act2_y_var = np.sum(np.var(reshaped_act2_y, axis = 0));\n",
    "    reshaped_act2_y = possibly_ravel(reshaped_act2_y)\n",
    "    verbose_print(verbose, 'Var2 is ' + str(act2_y_var))\n",
    "    \n",
    "    \n",
    "    \n",
    "    verbose_print(verbose, 'Training Est12 ' + ' with shapes of ' + str(np.shape(reshaped_act1_x)) + ', ' + str(np.shape(reshaped_act2_y)));\n",
    "    \n",
    "#    est_12 =  sklearn.linear_model.MultiTaskLassoCV();\n",
    "    est_12 = possibly_multitask_lasso_cv(reshaped_act2_y)\n",
    "    verbose_print(verbose, 'Training Est12 ' + str(type(est_12)) +  ' with shapes of ' + str(np.shape(reshaped_act1_x)) + ', ' + str(np.shape(reshaped_act2_y)));\n",
    "    \n",
    "#    verbose_print(verbose, 'Est12 has type ' + str(est_12))\n",
    "    est_12.fit(reshaped_act1_x, reshaped_act2_y); \n",
    "    est_12_frac_var_exp = est_12.score(reshaped_act1_x, reshaped_act2_y)\n",
    "#    est_12_tot_var = np.sum(np.var(reshaped_act2_y, axis = 1)); This is fudged to be 1 at the moment\n",
    "\n",
    "    \n",
    "    est_21 = possibly_multitask_lasso_cv(reshaped_act1_y)\n",
    "    verbose_print(verbose, 'Training Est21' + str(type(est_21)) + ' with shapes of ' + str(np.shape(reshaped_act2_x)) + ', ' + str(np.shape(reshaped_act1_y)));\n",
    "    \n",
    "    verbose_print(verbose, 'Est21 has type ' + str(est_21))\n",
    "    est_21.fit(reshaped_act2_x, reshaped_act1_y); \n",
    "    est_21_frac_var_exp = est_21.score(reshaped_act2_x, reshaped_act1_y)\n",
    "#    est_21_tot_var = np.sum(np.var(reshaped_act1_y, axis = 1));\n",
    "\n",
    "    verbose_print(verbose, 'Finished!')\n",
    "    \n",
    "    \n",
    "    return (est_21_frac_var_exp * act1_y_var, act1_y_var, est_12_frac_var_exp * act2_y_var, act2_y_var, est_21, est_12)\n",
    "\n",
    "    \n",
    "def lasso_var_exp(act1, act2, ind_to_use):\n",
    "    est_12 =  sklearn.linear_model.LassoCV();\n",
    "    est_12.fit(act1, act2[:, ind_to_use])\n",
    "    est_12_frac_var_exp = est_12.score(act1, act2[:, ind_to_use])\n",
    "    est_12_tot_var = np.var(act2[:, ind_to_use]);\n",
    "    \n",
    "    est_21 =  sklearn.linear_model.LassoCV();\n",
    "    est_21.fit(act2, act1[:, ind_to_use])\n",
    "    est_21_frac_var_exp = est_21.score(act2, act1[:, ind_to_use])\n",
    "    est_21_tot_var = np.var(act1[:, ind_to_use]);\n",
    "    \n",
    "    return (est_21_frac_var_exp * est_21_tot_var, est_21_tot_var, est_12_frac_var_exp * est_12_tot_var, est_12_tot_var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subroutines for filling and querying datastructures for calculated quantities\n",
    "\n",
    "\n",
    "####  The basic pattern is a fill up a dictionary with values which depend on the model, channel, layer, and possibly the class to be linearly separated. After doing so, the data can be sliced whichever way by querying the dictionary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def model_name_string(bottleneck_width, brain_layers, instance, noise_start = 0.0, noise_end = 0.0,\n",
    "                      retina_out_weight_reg = 0.0, retina_out_stride = 1, retina_hidden_channels = 32,\n",
    "                      task = 'classification', filter_size = 9, retina_layers = 2, use_b = 1, actreg = 0.0,\n",
    "                      vvs_width = 32, epochs = 20, reg = 0.0):\n",
    "\n",
    "    trial_label = instance\n",
    "    vvs_layers = brain_layers\n",
    "    retina_out_width = bottleneck_width\n",
    "\n",
    "\n",
    "    gen_model_name = 'cifar10_type_'+str(trial_label)+'_noise_start_'+str(noise_start)+'_noise_end_'+str(noise_end)+'_reg_'+str(reg)+'_retina_reg_'+str(retina_out_weight_reg)+'_retina_hidden_channels_'+str(retina_hidden_channels)+'_SS_'+str(retina_out_stride)+'_task_'+task+'_filter_size_'+str(filter_size)+'_retina_layers_'+str(retina_layers)+'_vvs_layers'+str(vvs_layers)+'_bias_'+str(use_b)+'_actreg_'+str(actreg)+'_retina_out_channels_'+str(retina_out_width)+'_vvs_width_'+str(vvs_width)+'_epochs_'+str(epochs)\n",
    "    gen_model_name = 'saved_models/SAVED'+'_'+gen_model_name\n",
    "\n",
    "    return gen_model_name\n",
    "\n",
    "\n",
    "print(model_name_string(brain_layers=2, instance=4, bottleneck_width=4))\n",
    "\n",
    "def create_model_name_list(bottleneck_width_list, brain_layers_list, instance_list):\n",
    "    model_name_list = [];\n",
    "    for cur_instance in instance_list:\n",
    "        for cur_brain_layers in brain_layers_list:    \n",
    "            for cur_bottleneck_width in bottleneck_width_list:\n",
    "                cur_model_name = model_name_string(bottleneck_width = cur_bottleneck_width, brain_layers = cur_brain_layers, instance = cur_instance)\n",
    "                model_name_list.append(cur_model_name)\n",
    "    return model_name_list\n",
    "\n",
    "\n",
    "def query_mean_sep_score(lin_sep_dict, model_name, n_classes = 10, layer = 3):\n",
    "    score_list = [];\n",
    "    for class1 in range(n_classes):\n",
    "        for class2 in range(class1+1,n_classes):\n",
    "            cur_score = lin_sep_dict[(model_name, layer, class1, class2)];\n",
    "            score_list.append(cur_score)\n",
    "    return np.mean(score_list)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def query_lin_sep_retina_plot_data(lin_sep_dict, bottleneck_width_list,brain_layer_list = range(5),  instance_list = range(1, 11, 1)):\n",
    "    #Make a list of means, stderrs, and legends to plot\n",
    "    all_plot_mean_stderr = [];\n",
    "    all_plot_legends = []\n",
    "\n",
    "    for (i_bottleneck_width, bottleneckwidth) in  enumerate(bottleneck_width_list):\n",
    "\n",
    "        cur_plot_mean_list  = [];\n",
    "        cur_plot_stderr_list = [];\n",
    "\n",
    "        for (i_brain_layers, brain_layers) in enumerate(brain_layer_list):\n",
    "            cur_val_list = []\n",
    "\n",
    "            for cur_instance in instance_list:\n",
    "                gen_model_name = model_name_string(bottleneck_width=bottleneckwidth, brain_layers=brain_layers, instance=cur_instance);\n",
    "              #  print(gen_model_name)\n",
    "                mean_score = query_mean_sep_score(my_lin_sep_dict, gen_model_name, layer=4, n_classes=10)\n",
    "                cur_val_list.append(2 * mean_score)\n",
    "            cur_plot_mean_list.append(np.mean(cur_val_list))\n",
    "            cur_plot_stderr_list.append(np.std(cur_val_list)/np.sqrt(len(cur_val_list)-1))\n",
    "\n",
    "\n",
    "        all_plot_mean_stderr.append((cur_plot_mean_list, cur_plot_stderr_list) )\n",
    "#        all_plot_legends.append(str(bottleneckwidth) + ' channels')\n",
    "\n",
    "        if(0):\n",
    "            print('PLOT MEAN LIST:')\n",
    "            print(cur_plot_mean_list)\n",
    "\n",
    "            print('PLOT STDERR LIST:')\n",
    "            print(cur_plot_stderr_list)\n",
    "        fig_legend_list.append(str(bottleneckwidth) + ' channels')\n",
    "\n",
    "    return( all_plot_mean_stderr, fig_legend_list)\n",
    "\n",
    "def query_lin_sep_vs_layer_plot_data(lin_sep_dict, bottleneck_width_list, layer_list = [0, 4,6, 8, 10, 12],\n",
    "                                     instance_list = range(1, 9, 1), brain_layers = 4):\n",
    "    #Make a list of means, stderrs, and legends to plot\n",
    "    all_plot_mean_stderr = [];\n",
    "    all_plot_legends = []\n",
    "\n",
    "    for (i_bottleneck_width, bottleneckwidth) in  enumerate(bottleneck_width_list):\n",
    "\n",
    "        cur_plot_mean_list  = [];\n",
    "        cur_plot_stderr_list = [];\n",
    "\n",
    "        for (i_layer, layer) in enumerate(layer_list):\n",
    "            cur_val_list = []\n",
    "\n",
    "            for cur_instance in instance_list:\n",
    "                gen_model_name = model_name_string(bottleneck_width=bottleneckwidth, brain_layers=brain_layers, instance=cur_instance);\n",
    "              #  print(gen_model_name)\n",
    "#                print('Doing layer' + str(layer))\n",
    "                mean_score = query_mean_sep_score(my_lin_sep_dict, gen_model_name, layer=layer, n_classes=10)\n",
    "                cur_val_list.append(2 * mean_score)\n",
    "            cur_plot_mean_list.append(np.mean(cur_val_list))\n",
    "            cur_plot_stderr_list.append(np.std(cur_val_list)/np.sqrt(len(cur_val_list)-1))\n",
    "\n",
    "\n",
    "        all_plot_mean_stderr.append((cur_plot_mean_list, cur_plot_stderr_list) )\n",
    "        all_plot_legends.append(str(bottleneckwidth) + ' channels')\n",
    "\n",
    "        if(0):\n",
    "            print('PLOT MEAN LIST:')\n",
    "            print(cur_plot_mean_list)\n",
    "\n",
    "            print('PLOT STDERR LIST:')\n",
    "            print(cur_plot_stderr_list)\n",
    "        fig_legend_list.append(str(bottleneckwidth) + ' channels')\n",
    "\n",
    "    return( all_plot_mean_stderr, all_plot_legends)\n",
    "\n",
    "\n",
    "def query_linearity_retina_plot_data(linearity_dict, bottleneck_width_list,brain_layer_list = range(5), instance_list = range(1, 9, 1), layer = 3):\n",
    "    #Make a list of means, stderrs, and legends to plot\n",
    "    all_plot_mean_stderr = [];\n",
    "    all_plot_legends = []\n",
    "\n",
    "    for (i_bottleneck_width, bottleneckwidth) in  enumerate(bottleneck_width_list):\n",
    "\n",
    "        cur_plot_mean_list  = [];\n",
    "        cur_plot_stderr_list = [];\n",
    "\n",
    "        for (i_brain_layers, brain_layers) in enumerate(brain_layer_list):\n",
    "            cur_val_list = []\n",
    "\n",
    "            for cur_instance in instance_list:\n",
    "                gen_model_name = model_name_string(bottleneck_width=bottleneckwidth, brain_layers=brain_layers, instance=cur_instance);\n",
    "                cur_return_dict = linearity_dict[(gen_model_name, layer)]\n",
    "                cur_val_list.append(cur_return_dict['frac_var_exp']);\n",
    "            cur_plot_mean_list.append(np.mean(cur_val_list))\n",
    "            cur_plot_stderr_list.append(np.std(cur_val_list)/np.sqrt(len(cur_val_list)-1))\n",
    "\n",
    "\n",
    "        all_plot_mean_stderr.append((cur_plot_mean_list, cur_plot_stderr_list) )\n",
    "#        all_plot_legends.append(str(bottleneckwidth) + ' channels')\n",
    "\n",
    "        if(1):\n",
    "            print('PLOT MEAN LIST:')\n",
    "            print(cur_plot_mean_list)\n",
    "\n",
    "            print('PLOT STDERR LIST:')\n",
    "            print(cur_plot_stderr_list)\n",
    "        fig_legend_list.append(str(bottleneckwidth) + ' channels')\n",
    "\n",
    "    return(all_plot_mean_stderr, all_plot_legends)\n",
    "\n",
    "        \n",
    "def query_chanwise_sep_score(lin_sep_dict, model_name, n_classes = 10, layer = 3, n_channels = 1):\n",
    "    all_chan_score_list =  []\n",
    "    for chan in range(n_channels):\n",
    "        cur_chan_score_list = [];\n",
    "        for class1 in range(n_classes):\n",
    "            for class2 in range(class1+1,n_classes):\n",
    "                cur_score = lin_sep_dict[(model_name, layer, class1, class2, chan)];\n",
    "                cur_chan_score_list.append(cur_score)\n",
    "        all_chan_score_list.append(np.mean(cur_chan_score_list))\n",
    "    return all_chan_score_list\n",
    "#    return np.mean(score_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "# Calculate Linear Separability and linearity of channels\n",
    "--------------------------------------\n",
    "#### This fills up several large dictionary structures, which will be queried to make plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "## measure linear separability in pixel space with SVM\n",
    "#for each layer, load activations\n",
    "\n",
    "from keras.datasets import cifar10\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "y_test2 = y_test.copy()\n",
    "\n",
    "\n",
    "model_SVM = sklearn.svm.LinearSVC(penalty='l2', loss='squared_hinge', dual=True, tol=0.0001, C=1.0, \n",
    "                      multi_class='ovr', fit_intercept=True, intercept_scaling=1, class_weight=None, \n",
    "                      verbose=0, random_state=None, max_iter=1000)\n",
    "if(0):\n",
    "    my_lin_fit_dict = dict();\n",
    "    my_im_fit_dict = dict();    \n",
    "    my_lin_sep_dict = dict();\n",
    "    my_chanwise_lin_sep_dict = dict();\n",
    "else:\n",
    "    # We can either make new dictionary or load ones we have to calculate more values \n",
    "    my_lin_sep_dict = big_pickle_load('AnalysisOutputs/LinSeparationDict.p')\n",
    "    my_lin_fit_dict = big_pickle_load('AnalysisOutputs/LinFitDict.p')\n",
    "    my_chanwise_lin_sep_dict = big_pickle_load('AnalysisOutputs/ChanwiseLinSeparationDict.p')\n",
    "    my_im_fit_dict = big_pickle_load('AnalysisOutputs/ImFitdict.p')\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "bottleneck_width_list = [1,32]\n",
    "#bottleneck_width_list = [1, 2, 4, 8, 16, 32]\n",
    "instance_list = list(range(1, 11, 1)) #Instances MUST start from 1\n",
    "#brain_layers_list = [0, 1, 2, 3, 4]\n",
    "brain_layers_list = [4]\n",
    "\n",
    "\n",
    "n_classes_to_do = 10; #We linearly separate all possible pairs of classes. \n",
    "#By setting this number to be  less than 10, we can make things run faster\n",
    "#layers_to_do = [3];\n",
    "layers_to_do = [0, 2, 4, 5, 6, 7]\n",
    "\n",
    "#Layer 0 is the image, layer 2 is the first layer of Retina_Net, layer 3 is the bottleneck, and layers 4, 5, 6,7 are the activations in VVS-Nett\n",
    "\n",
    "#all_model_names = os.listdir(model_input_path);\n",
    "#all_model_names = [all_model_names[0]]\n",
    "all_model_names = create_model_name_list(bottleneck_width_list, brain_layers_list, instance_list)\n",
    "print('N models is ' + str(len(all_model_names)))\n",
    "#all_model_names = all_model_names[0:]; \n",
    "#print('N Clipped models is ' + str(len(all_model_names)))\n",
    "\n",
    "\n",
    "\n",
    "#all_model_names = all_model_names[43:]\n",
    "for (i_model_name, model_name) in enumerate(all_model_names):\n",
    "    print('\\n\\nDoing model '   +  str(i_model_name) + ' /'  + str(len(all_model_names)) )\n",
    "    print('Name:' + model_name)\n",
    "    print(time.asctime())\n",
    "    \n",
    "    model_nlayers_filename = pickle_dir +  'NLayersOf_' + model_name + '.p';\n",
    "    model_nlayers = big_pickle_load(model_nlayers_filename);\n",
    "    pixels_act = load_layer_activations_from_batch_files(model_name, layer=0, verbose=False)\n",
    "    \n",
    "\n",
    "    \n",
    "    cur_layers_to_keep = layers_to_do\n",
    "#    cur_layers_to_keep = [0, 3] + list(range(4, model_nlayers, 2));    \n",
    "    for cur_layer in cur_layers_to_keep:\n",
    "        print('Calculating Properties of Layer', cur_layer)\n",
    "        # load activation\n",
    "        \n",
    "        act = load_layer_activations_from_batch_files(model_name, cur_layer, verbose=False)\n",
    "        print('Loaded activations of shape ' + str(np.shape(act)))\n",
    "        \n",
    "        \n",
    "        if(1):\n",
    "            #Calculates linear fits between image and activations\n",
    "            print('Calculating linear fit from image to layer')\n",
    "            cur_return_dict = one_way_multi_channel_ridge_var_exp(act_1 = pixels_act, act_2 = act, verbose=True);\n",
    "            my_lin_fit_dict[(model_name, cur_layer)] = cur_return_dict\n",
    "        if(1):\n",
    "            print('Calculating linear fit from layer to image')            \n",
    "            cur_return_dict = one_way_multi_channel_ridge_var_exp(act_1 = act, act_2 = pixels_act, verbose=True);\n",
    "            my_im_fit_dict[(model_name, cur_layer)] = cur_return_dict\n",
    "            \n",
    "        if(0): \n",
    "            #Calcualates Linear Class Separabililty Channel By channel            \n",
    "            #for each pair of class, measure linear separability on testing set\n",
    "            i = 0\n",
    "            for chan in range(np.shape(act)[3]):\n",
    "                print('Doing Channel-Wise Separability for Channel ' + str(chan))\n",
    "                \n",
    "                cur_chan_acts = act[:, :, :, chan]\n",
    "                cur_chan_acts = cur_chan_acts.reshape(cur_chan_acts.shape[0],cur_chan_acts.shape[1]*cur_chan_acts.shape[2])\n",
    "\n",
    "                for class1 in range(n_classes_to_do):\n",
    "                    for class2 in range(class1+1,n_classes_to_do):\n",
    " #                       print('Comparing classes ' +str((class1, class2)))\n",
    " #                       print(time.asctime())\n",
    "\n",
    "                        #print(class2)\n",
    "                        keep = np.squeeze((y_test2==class1) + (y_test2==class2))\n",
    "                        actk = cur_chan_acts[keep]\n",
    "                        yk = y_test[keep]\n",
    "                        yk = yk==class1\n",
    "                        #y = y_test2==class1\n",
    "                        #y = y_test2==class2\n",
    "                        model_SVM.fit(actk[:1000], yk[:1000])\n",
    "                        pred = np.squeeze(model_SVM.predict(actk[1000:]))\n",
    "                        real = np.squeeze(yk[1000:])\n",
    "                        score = np.mean(pred==real)- .5\n",
    "                        my_chanwise_lin_sep_dict[(model_name, cur_layer, class1, class2, chan)] = score;\n",
    "\n",
    "\n",
    "                        i = i+1\n",
    "\n",
    "#                        print('Score betwen classes ' +str((class1, class2))+' is' + str(score))\n",
    "        if(1): #Calculates Linear Class Separability as a whole\n",
    "            if (len(np.shape(act))>2):\n",
    "                act = act.reshape(act.shape[0],act.shape[1]*act.shape[2]*act.shape[3])\n",
    "            \n",
    "            #for each pair of class, measure linear separability on testing set\n",
    "            i = 0\n",
    "            print('Calculating All-Channel Linear Separability')\n",
    "            for class1 in range(n_classes_to_do):\n",
    "                for class2 in range(class1+1,n_classes_to_do):\n",
    "                    print('All-Channel Linear Separability, Comparing classes ' +str((class1, class2)))\n",
    "#                    print(time.asctime())\n",
    "\n",
    "                    #print(class2)\n",
    "                    keep = np.squeeze((y_test2==class1) + (y_test2==class2))\n",
    "                    actk = act[keep]\n",
    "                    yk = y_test[keep]\n",
    "                    yk = yk==class1\n",
    "                    #y = y_test2==class1\n",
    "                    #y = y_test2==class2\n",
    "                    model_SVM.fit(actk[:1000], yk[:1000])\n",
    "                    pred = np.squeeze(model_SVM.predict(actk[1000:]))\n",
    "                    real = np.squeeze(yk[1000:])\n",
    "                    score = np.mean(pred==real)- .5\n",
    "                    my_lin_sep_dict[(model_name, cur_layer, class1, class2)] = score;\n",
    "                    \n",
    "                    \n",
    "                    i = i+1\n",
    "#                    print('Score betwen classes ' +str((class1, class2))+' is' + str(score))\n",
    "    #We save the dictionary once we're done with each model.\n",
    "    #If there were too many models, this would be inefficient, but in practice this doesn't take too much time\n",
    "    ensure_dir('AnalysisOutputs/ImFitdict.p')\n",
    "    big_pickle_dump(my_im_fit_dict, 'AnalysisOutputs/ImFitdict.p')\n",
    "    big_pickle_dump(my_chanwise_lin_sep_dict, 'AnalysisOutputs/ChanwiseLinSeparationDict.p') \n",
    "    big_pickle_dump(my_lin_sep_dict, 'AnalysisOutputs/LinSeparationDict.p')\n",
    "    big_pickle_dump(my_lin_fit_dict, 'AnalysisOutputs/LinFitDict.p') \n",
    "    print('Finished with model ' + model_name)\n",
    "print('Finished making dictionaries!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "# Plots variance explained of linear fits or linear separability for various architectures\n",
    "\n",
    "\n",
    "### Organized as a bunch of nearly identical sections which plot different quantities\n",
    "\n",
    "\n",
    "##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "my_lin_sep_dict = big_pickle_load('AnalysisOutputs/LinSeparationDict.p')\n",
    "my_lin_fit_dict = big_pickle_load('AnalysisOutputs/LinFitDict.p')\n",
    "my_im_fit_dict = big_pickle_load('AnalysisOutputs/ImFitdict.p')\n",
    "new_colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728',\n",
    "              '#9467bd', '#8c564b', '#e377c2', '#7f7f7f',\n",
    "              '#bcbd22', '#17becf'];\n",
    "\n",
    "all_lines  =[]\n",
    "brain_layer_list = list(range(5));\n",
    "fig_legend_list = [];\n",
    "plot_line_format_list = [];\n",
    "if(0):\n",
    "    plot_line_format_list.append(('k', '-'))\n",
    "    plot_line_format_list.append(([.65, .65, .65], '-'))\n",
    "else:\n",
    "    \n",
    "    bottleneck_width_list  =[1, 2, 4, 8, 16, 32]\n",
    "    plot_line_format_list.append(('k', '-'))\n",
    "    \n",
    "    for color in new_colors:\n",
    "        plot_line_format_list.append((color, '-'))\n",
    "    \n",
    "    plot_line_format_list.append(('r', ':'))\n",
    "    plot_line_format_list.append(('g', ':'))\n",
    "    plot_line_format_list.append(('b', ':'))\n",
    "    plot_line_format_list.append(('purple', ':'))\n",
    "    plot_line_format_list.append(([.65, .65, .65], '-'))\n",
    "    \n",
    "#    plot_line_format_list.append(('purple', '--'))\n",
    "    \n",
    "plotted_model_names = []\n",
    "x_pad_r = .045\n",
    "x_pad_l = .06\n",
    "\n",
    "x_pad_r = .1\n",
    "x_pad_l = .1\n",
    "if(1):\n",
    "    bottleneck_width_list =  [1, 2, 4]\n",
    "               \n",
    "    #instance_list = list(range(1, 11, 1))\n",
    "    instance_list = list(range(1, 11, 1))\n",
    "\n",
    "    (mean_stderr_list, legend_list) = query_linearity_retina_plot_data(my_im_fit_dict, bottleneck_width_list)\n",
    "    plt.clf();\n",
    "    all_lines = []\n",
    "\n",
    "    for (i_bottleneck_width, (cur_means, cur_stderrs) ) in enumerate (mean_stderr_list):\n",
    "        cur_plot_line_format = plot_line_format_list[i_bottleneck_width];\n",
    "        cur_line  = plt.errorbar(brain_layer_list, cur_means, yerr = 2 *  np.array(cur_stderrs), c = cur_plot_line_format[0], linestyle = cur_plot_line_format[1], marker = 'o')\n",
    "        print('At ' + str(i_bottleneck_width))\n",
    "        all_lines.append(cur_line)\n",
    "        \n",
    "    #    plt.show()\n",
    "\n",
    "    plt.xlabel('N Brain Layers')\n",
    "    plt.ylabel('Linearity (Retina ->Image)')\n",
    "\n",
    "    plt.legend(tuple(all_lines), tuple(fig_legend_list))   \n",
    "    plt.ylim([.4, 1])\n",
    "    plt.ylim([.0, 1])\n",
    "    \n",
    "    plt.xlim([-x_pad_l + np.min(brain_layer_list), np.max(brain_layer_list)+x_pad_r])\n",
    "    plt.xticks(brain_layer_list)\n",
    "    fig_out_path = 'Outputs/ImageLinearityVsNLayers.pdf'    \n",
    "    ensure_dir(fig_out_path)\n",
    "    plt.savefig(fig_out_path)\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "if(1): ## Plot the linear separability of the retinal layer as a function the the number of layers and bottleneck width\n",
    "    #This is figure 3D\n",
    "    bottleneck_width_list = [1, 4]\n",
    "    instance_list = [1, 2]\n",
    "    brain_layers_list = [0, 1, 2, 3, 4]    \n",
    "#    bottleneck_width_list =  [1, 2, 4]    \n",
    "#    instance_list = list(range(1, 11, 1))\n",
    "\n",
    "    (mean_stderr_list, legend_list) = query_lin_sep_retina_plot_data(my_lin_sep_dict, bottleneck_width_list, instance_list=instance_list)\n",
    "    plt.clf();\n",
    "    all_lines = [];\n",
    "\n",
    "    for (i_bottleneck_width, (cur_means, cur_stderrs) ) in enumerate (mean_stderr_list):\n",
    "        cur_plot_line_format = plot_line_format_list[i_bottleneck_width];\n",
    "        cur_line  = plt.errorbar(brain_layer_list, cur_means, yerr = 2 * np.array(cur_stderrs), c = cur_plot_line_format[0], linestyle = cur_plot_line_format[1], marker = 'o')\n",
    "        print('At Bottleneck Width' + str(i_bottleneck_width))\n",
    "        all_lines.append(cur_line)\n",
    "        \n",
    "    if(1):\n",
    "        #Hardcoded in the linear separability of the image itself\n",
    "        cur_line, = plt.plot([0, 4], 1 * np.array([0.2738, 0.2738]), c = [.1, .1, .1], linestyle = '--');\n",
    "        all_lines.append(cur_line)\n",
    "        fig_legend_list.append('Raw Pixels')\n",
    "\n",
    "    plt.legend(tuple(all_lines), tuple(fig_legend_list))   \n",
    "    plt.ylim([.0, 1])\n",
    "    \n",
    "    plt.xlim([-x_pad_l + np.min(brain_layer_list), np.max(brain_layer_list)+x_pad_r])\n",
    "    plt.xticks(brain_layer_list)\n",
    "    fig_out_path = 'AnalysisOutputs/RetinaLinSepVsNLayers.pdf'    \n",
    "    ensure_dir(fig_out_path)\n",
    "    plt.savefig(fig_out_path)\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "\n",
    "if(1): #Plot the linearity of the bottleneck layer as a function of the number of layers and bottleneck width\n",
    "    #This is figure 3A\n",
    "    bottleneck_width_list = [1, 4]\n",
    "    #instance_list = list(range(1, 3, 1)) #Instances MUST start from 1\n",
    "    instance_list = [1, 2]\n",
    "    brain_layers_list = [0, 1, 2, 3, 4]\n",
    "    \n",
    "#    bottleneck_width_list =  [1, 2, 4]    \n",
    "    #instance_list = list(range(1, 11, 1))\n",
    "#    instance_list = list(range(1, 11, 1))\n",
    "\n",
    "    (mean_stderr_list, legend_list) = query_linearity_retina_plot_data(my_lin_fit_dict, bottleneck_width_list, instance_list=instance_list)\n",
    "    plt.clf();\n",
    "    all_lines = [];\n",
    "    for (i_bottleneck_width, (cur_means, cur_stderrs) ) in enumerate (mean_stderr_list):\n",
    "        cur_plot_line_format = plot_line_format_list[i_bottleneck_width];\n",
    "        cur_line  = plt.errorbar(brain_layer_list, cur_means, yerr =  2 * np.array(cur_stderrs), c = cur_plot_line_format[0], linestyle = cur_plot_line_format[1], marker = 'o')\n",
    "        print('At ' + str(i_bottleneck_width))\n",
    "        all_lines.append(cur_line)\n",
    "\n",
    "#    plt.xlabel('N Brain Layers')\n",
    "#    plt.ylabel('Linearity (Image ->Retina)')\n",
    "\n",
    "#    plt.legend(tuple(all_lines), tuple(fig_legend_list))   \n",
    " #   plt.ylim([.4, 1])\n",
    "    plt.xlim([-x_pad_l + np.min(brain_layer_list), np.max(brain_layer_list)+x_pad_r])\n",
    "    plt.xticks(brain_layer_list)\n",
    "    fig_out_path = 'AnalysisOutputs/RetinaLinearityVsNLayers.pdf'    \n",
    "    ensure_dir(fig_out_path)\n",
    "    plt.savefig(fig_out_path)\n",
    "    plt.show()\n",
    "    \n",
    "if(1): #Plots the linear separaiblity for each layer\n",
    "    print('Doing linear separability for each layer!')\n",
    "    bottleneck_width_list =  [1]\n",
    "               \n",
    "    #I currently only have these for the extreme bottlenecks\n",
    "    bottleneck_width_list =  [1, 32]\n",
    "    plot_line_format_list = [];\n",
    "    plot_line_format_list.append(('k', '-'))\n",
    "    plot_line_format_list.append(([.5, .5, .5], '-'))\n",
    "    \n",
    "    #instance_list = list(range(1, 11, 1))\n",
    "    instance_list = list(range(1, 9, 1))\n",
    "#    instance_list = [1]\n",
    "\n",
    "    lin_sep_layer_list = [0,2, 3, 4, 5, 6, 7]\n",
    "    (mean_stderr_list, legend_list) = query_lin_sep_vs_layer_plot_data(my_lin_sep_dict, bottleneck_width_list, layer_list=lin_sep_layer_list, instance_list=instance_list)\n",
    "    plt.clf();\n",
    "    all_lines = []\n",
    "\n",
    "    for (i_bottleneck_width, (cur_means, cur_stderrs) ) in enumerate (mean_stderr_list):\n",
    "        cur_plot_line_format = plot_line_format_list[i_bottleneck_width];\n",
    "        cur_line  = plt.errorbar(np.array(lin_sep_layer_list)/2, cur_means, yerr = 2 *  np.array(cur_stderrs), c = cur_plot_line_format[0], linestyle = cur_plot_line_format[1], marker = 'o')\n",
    "        print('At ' + str(i_bottleneck_width))\n",
    "        all_lines.append(cur_line)\n",
    "        \n",
    "    plt.xlim([-x_pad_l + np.min(np.array(lin_sep_layer_list)/2), np.max(np.array(lin_sep_layer_list)/2)+x_pad_r])\n",
    "    plt.xticks(np.array(lin_sep_layer_list)/2)\n",
    "    fig_out_path = 'AnalysisOutputs/LinSepVsLayerDepth.pdf'    \n",
    "    ensure_dir(fig_out_path)\n",
    "    plt.savefig(fig_out_path)\n",
    "    plt.show()    \n",
    "print('Finished Making All Plots!')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot linear separability vs linearity for invidiual channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if(0):\n",
    "    my_lin_fit_dict = dict();\n",
    "    my_lin_sep_dict = dict();\n",
    "    my_chanwise_lin_sep_dict = dict();\n",
    "else:\n",
    "    my_lin_sep_dict = big_pickle_load('AnalysisOutputs/LinSeparationDict.p')\n",
    "    my_lin_fit_dict = big_pickle_load('AnalysisOutputs/LinFitDict.p')\n",
    "    my_chanwise_lin_sep_dict = big_pickle_load('AnalysisOutputs/ChanwiseLinSeparationDict.p')\n",
    "#    bottleneck_width_list = [1, 2, 4, 8, 16, 32]\n",
    "    bottleneck_width_list = [4]\n",
    "    \n",
    "    #instance_list = [1,2,3]\n",
    "    instance_list = list(range(1, 10, 1)) #Instances MUST start from 1\n",
    "    brain_layers_list = list(range(5))\n",
    "#    brain_layers_list = [4]\n",
    "    n_classes_to_do = 10;\n",
    "\n",
    "    \n",
    "\n",
    "instance_list = range(1, 11, 1)\n",
    "\n",
    "#print(my_lin_fit_dict.keys())\n",
    "#print(my_chanwise_lin_sep_dict.keys())\n",
    "#filled_markers = ('A', 'B', 'C', 'D', 'E')\n",
    "#p\n",
    "filled_markers = ('o', '|', '^', 's', 'p') #Shapes up to pentagon\n",
    "#instance_list = range(1,9, 1)\n",
    "#filled_markers = ('x', 'v', 'o', '^', '8')\n",
    "my_other_colors = ('k', 'r', 'g', 'b', 'c', 'm', 'y', '#000066', [.3, .3, .3], [.75, .75, .75])\n",
    "my_colors = ('#000066','#3333cc','#cc33ff','#ff3399','#ff9966','#FFD700', '#99ff66')\n",
    "#my_colors = ('#000066', #3333cc, #cc33ff, #ff3399, #ff9966, #ff9966, #ffff99)\n",
    "if(1):\n",
    "    plt.clf();\n",
    "#    my_chanwise_linsep_list =  []\n",
    "#    my_chanwise_lin_fit_list = []\n",
    "    \n",
    "    cur_layer = 3\n",
    "    #for (iblayers, blayers) in enumerate(brain_layers_list):\n",
    "    for (ibneckwidth, bneckwidth) in enumerate(bottleneck_width_list):\n",
    "        \n",
    "        mega_x_list = [];\n",
    "        mega_y_list = [];\n",
    "        mega_color_list = []\n",
    "        mega_marker_list = []\n",
    "        mega_fmt_list = []\n",
    "\n",
    "        plt.clf()\n",
    "        plt.figure(figsize=(20,10))   \n",
    "\n",
    "        my_chanwise_linsep_list =  []\n",
    "        my_chanwise_lin_fit_list = []\n",
    "#        for (ibneckwidth, bneckwidth) in enumerate(bottleneck_width_list):\n",
    "        for (iblayers, blayers) in enumerate(brain_layers_list):\n",
    "                    \n",
    "            all_cur_model_names = create_model_name_list(bottleneck_width_list = [bneckwidth], brain_layers_list = [blayers], instance_list =  instance_list)\n",
    "            cur_arch_y_list = [];\n",
    "            cur_arch_x_list = [];\n",
    "            \n",
    "            cur_arch_color_list = []\n",
    "            cur_arch_marker_list = []\n",
    "            cur_arch_fmt_list = []\n",
    "            \n",
    "            for (imname, model_name) in enumerate(all_cur_model_names):\n",
    "                print('IModelName is '+ str(imname))\n",
    "                cur_lin_sep_list = query_chanwise_sep_score(my_chanwise_lin_sep_dict, model_name = model_name, n_classes=n_classes_to_do, layer=cur_layer, n_channels= bneckwidth);\n",
    "#                cur_lin_sep_list = query_chanwise_sep_score(my_chanwise_lin_sep_dict, model_name = model_name, n_classes=n_classes_to_do, layer=cur_layer, n_channels= 32);\n",
    "                \n",
    "                my_chanwise_linsep_list.extend(cur_lin_sep_list);\n",
    "                cur_lin_fit_element = my_lin_fit_dict[(model_name, cur_layer)]\n",
    "                cur_lin_fit_list = cur_lin_fit_element['chan_wise_scores'];\n",
    "                my_chanwise_lin_fit_list.extend(cur_lin_fit_list)\n",
    "                \n",
    "                \n",
    "                cur_n_points = len(cur_lin_fit_list)\n",
    "                print('Lin fit, lin sep have ' + str((len(cur_lin_fit_list), len(cur_lin_sep_list))))\n",
    "                mega_x_list.extend(cur_lin_fit_list)\n",
    "                mega_y_list.extend(cur_lin_sep_list)\n",
    "                cur_color = my_colors[iblayers]\n",
    "                cur_marker = 'o'\n",
    "                \n",
    "#                cur_marker = filled_markers[ibneckwidth]\n",
    "                \n",
    "                mega_color_list.extend([cur_color] * cur_n_points)\n",
    "                mega_marker_list.extend([cur_marker] * cur_n_points)\n",
    "                mega_fmt_list.extend([cur_color + cur_marker] * cur_n_points)\n",
    "\n",
    "                cur_arch_y_list.extend(cur_lin_sep_list)\n",
    "                cur_arch_x_list.extend(cur_lin_fit_list)\n",
    "                cur_arch_color_list.extend([my_other_colors[imname]] * len(cur_lin_sep_list))\n",
    "            if(1):\n",
    "                plt.figure(figsize=(20,10))   \n",
    "\n",
    "                for i in list(reversed(range(len(cur_arch_y_list)))):\n",
    "    #                plt.plot(mega_x_list[i], mega_y_list[i], color = mega_color_list[i], marker =  mega_marker_list[i], linestyle = '')\n",
    "                    plt.plot(cur_arch_x_list[i], cur_arch_y_list[i], color = cur_arch_color_list[i], marker =  'o', linestyle = '', alpha = .5, markersize = 40)\n",
    "\n",
    "            #    plt.scatter(mega_x_list, mega_y_list, color = mega_color_list)\n",
    "            #    plt.scatter(mega_x_list, mega_y_list, mega_fmt_list[0])\n",
    "\n",
    "                plt.ylabel('Separability')\n",
    "                plt.xlabel('Linearity')\n",
    "    #            plt.title('Brain Layers ' + str(blayers))\n",
    "                plt.title('Instances of Bneck, Depth ' + str((bneckwidth, blayers)) )\n",
    "\n",
    "                plt.show()\n",
    "                plt.clf()                \n",
    "                \n",
    "             #   plt.scatter(cur_lin_fit_list, cur_lin_sep_list)\n",
    "\n",
    "\n",
    "#            print(np.shape(my_chanwise_linsep_list))\n",
    "#            print(np.shape(my_chanwise_lin_fit_list))\n",
    "\n",
    "#            print(my_chanwise_linsep_list)\n",
    "#            print(my_chanwise_lin_fit_list)\n",
    "            cur_color = my_colors[ibneckwidth]\n",
    "#            cur_color = 'k'\n",
    "    \n",
    "            cur_marker = filled_markers[iblayers]\n",
    "#            cur_marker = '.'\n",
    "        \n",
    "#            cur_marker = filled_markers[iblayers]\n",
    "            \n",
    "            print((cur_color, cur_marker))\n",
    "            cur_fmt = cur_color+cur_marker;\n",
    "            cur_n = len(my_chanwise_lin_fit_list)\n",
    "            print(cur_n)\n",
    "#            plt.scatter(my_chanwise_lin_fit_list, my_chanwise_linsep_list, color = [cur_color] * cur_n, marker = [cur_marker] * cur_n)\n",
    "#            plt.scatter(my_chanwise_lin_fit_list, my_chanwise_linsep_list, color = [cur_color] * cur_n,  marker = cur_marker)\n",
    "#            plt.scatter(my_chanwise_lin_fit_list, my_chanwise_linsep_list, color = cur_color,  marker = cur_marker)\n",
    "            #plt.plot(my_chanwise_lin_fit_list, my_chanwise_linsep_list, linestyle='', color = cur_color, marker = cur_marker)\n",
    "            \n",
    "#            plt.scatter(my_chanwise_lin_fit_list, my_chanwise_linsep_list, color = cur_color, marker = cur_marker)\n",
    "            if(1):\n",
    "                plt.figure(figsize=(20,10))   \n",
    "\n",
    "                for i in list(reversed(range(len(mega_x_list)))):\n",
    "    #                plt.plot(mega_x_list[i], mega_y_list[i], color = mega_color_list[i], marker =  mega_marker_list[i], linestyle = '')\n",
    "                    plt.plot(mega_x_list[i], mega_y_list[i], color = mega_color_list[i], marker =  mega_marker_list[i], linestyle = '', alpha = .5, markersize = 15)\n",
    "\n",
    "            #    plt.scatter(mega_x_list, mega_y_list, color = mega_color_list)\n",
    "            #    plt.scatter(mega_x_list, mega_y_list, mega_fmt_list[0])\n",
    "\n",
    "                plt.ylabel('Separability')\n",
    "                plt.xlabel('Linearity')\n",
    "    #            plt.title('Brain Layers ' + str(blayers))\n",
    "                plt.title('Bneck ' + str(bneckwidth))\n",
    "\n",
    "                plt.show()\n",
    "                plt.clf()\n",
    "\n",
    "    if(0):\n",
    "        plt.ylabel('Separability')\n",
    "        plt.xlabel('Linearity')\n",
    "        plt.show()\n",
    "        plt.clf();\n",
    "        print('Here!')\n",
    "    \n",
    "\n",
    "#plt.show()\n",
    "if(0):\n",
    "    for model_name in all_model_names:\n",
    "        cur_lin_sep_list = query_chanwise_sep_score(my_chanwise_lin_sep_dict, model_name = model_name, n_classes=n_classes_to_do, layer=cur_layer, n_channels= 32);\n",
    "        my_chanwise_linsep_list.extend(cur_lin_sep_list);\n",
    "        cur_lin_fit_element = my_lin_fit_dict[(model_name, cur_layer)]\n",
    "        cur_lin_fit_list = cur_lin_fit_element['chan_wise_scores'];\n",
    "        my_chanwise_lin_fit_list.extend(cur_lin_fit_list)\n",
    "        plt.scatter(cur_lin_fit_list, cur_lin_sep_list)\n",
    "\n",
    "\n",
    "    print(np.shape(my_chanwise_linsep_list))\n",
    "    print(np.shape(my_chanwise_lin_fit_list))\n",
    "\n",
    "    print(my_chanwise_linsep_list)\n",
    "    print(my_chanwise_lin_fit_list)\n",
    "    #plt.scatter(my_chanwise_lin_fit_list, my_chanwise_linsep_list)\n",
    "    #plt.ylabel('Separability')\n",
    "    #plt.xlabel('Linearity')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "# Pickle All models\n",
    "\n",
    "### Here we pickle all model activations to load later. While this must be run first, we only need to do this once, so it's at the bottom "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "\n",
    "import keras.backend as K\n",
    "K.set_image_data_format('channels_last')\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Conv2D, ZeroPadding2D, BatchNormalization, Input\n",
    "from keras.layers import Conv2DTranspose, Reshape, Activation, Cropping2D, Flatten\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.activations import relu\n",
    "from keras.initializers import RandomNormal\n",
    "from keras.optimizers import RMSprop, SGD, Adam\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "import math\n",
    "import os\n",
    "import sys  \n",
    "\n",
    "\n",
    "\n",
    "should_load_models = False\n",
    "should_pickle_activations = False;\n",
    "should_pickle_n_layers = False;\n",
    "\n",
    "should_try_to_load_all_pickles = True\n",
    "\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "x_train = np.mean(x_train, 3, keepdims=True)\n",
    "x_test = np.mean(x_test, 3, keepdims=True) \n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "num_classes = 10\n",
    "\n",
    "y_train2 = y_train.copy()\n",
    "y_test2 = y_test.copy()\n",
    "\n",
    "# Convert class vectors to binary class matrices.\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "keras.__version__\n",
    "\n",
    "##############^^^IMPORT DATASET^^^####################\n",
    "\n",
    "\n",
    "#model_input_path = '../../COMMON/PickleJar/'\n",
    "\n",
    "import os\n",
    "untrimmed_model_names = os.listdir(model_input_path);\n",
    "#all_model_names = untrimmed_model_names[0:4]\n",
    "\n",
    "all_model_names = untrimmed_model_names[0:300]\n",
    "from keras.models import load_model\n",
    "full_size_to_use = 10000;\n",
    "batch_size_to_use = 200;\n",
    "\n",
    "if(should_load_models):\n",
    "    for (i_model, cur_model_name) in enumerate(all_model_names):\n",
    "        keras.backend.clear_session()\n",
    "\n",
    "        print(cur_model_name + '\\n')\n",
    "        print('Loading model ' + str(i_model) + '/' +  str(len(all_model_names)) + '...' )\n",
    "        cur_model = load_model(model_input_path + '/' + cur_model_name)\n",
    "        cur_layers_to_keep = [0,2,  3] + list(range(4, len(cur_model.layers)));\n",
    "#        cur_layers_to_keep = [0, 4, 6];\n",
    "\n",
    "        print('Finished Loading model')    \n",
    "        if(should_pickle_activations):\n",
    "            output_activations_to_pickle(cur_model, x_test, cur_layers_to_keep, cur_model_name, verbose = False, batch_size = batch_size_to_use, full_size = full_size_to_use, make_batches = True, compile_batches = False, delete_batches_when_done = False)   \n",
    "            print('Finished pickling acts of size' + str(full_size_to_use))\n",
    "        if(should_pickle_n_layers):\n",
    "            cur_model_n_layers =  len(cur_model.layers);\n",
    "            cur_path_name = pickle_dir + '/' + 'NLayersOf_' + cur_model_name + '.p';\n",
    "            print('Dumped n_layers ' + str(cur_model_n_layers))\n",
    "            print('\\n\\n' + cur_path_name + '\\n\\n')\n",
    "            big_pickle_dump(cur_model_n_layers, cur_path_name)\n",
    "        \n",
    "\n",
    "    print('Finished Making Batches!')\n",
    "        \n",
    "if(should_try_to_load_all_pickles):    \n",
    "    print('At last bit of conditional, just loading and viewing')\n",
    "    print(time.asctime());\n",
    "    for (i_model, cur_model_name) in enumerate(all_model_names):\n",
    "        keras.backend.clear_session()\n",
    "    \n",
    "        print(cur_model_name + '\\n')\n",
    "        if(0):\n",
    "            #This is what we do if we don't have a model name\n",
    "            print('Loading model ' + str(i_model) + '/' +  str(len(all_model_names)) + ' ...' )\n",
    "            cur_model = load_model(model_input_path + '/' + cur_model_name)\n",
    "            cur_layers_to_keep = [0,2,  3] + list(range(4, len(cur_model.layers)));\n",
    "            \n",
    "#            cur_layers_to_keep = [0, 3] + list(range(4, len(cur_model.layers), 2));\n",
    "        else:\n",
    "            \n",
    "            cur_path_name = pickle_dir + '/' + 'NLayersOf_' + cur_model_name + '.p';\n",
    "            cur_model_n_layers = pickle.load(open(cur_path_name, 'rb'))\n",
    "#            cur_layers_to_keep = [0, 3] + list(range(4, cur_model_n_layers, 2));\n",
    "#            cur_layers_to_keep = [0, 4, 6];            \n",
    "            cur_layers_to_keep = [0,2,  3] + list(range(4, len(cur_model.layers)));\n",
    "\n",
    "            print('Model ' + str(i_model) + '/' +  str(len(all_model_names)) + 'Has ' + str(cur_model_n_layers) + ' Layers' )\n",
    "            print(time.asctime())\n",
    "\n",
    "\n",
    "        for cur_layer in cur_layers_to_keep:\n",
    "            print('Loading Layer ' + str(cur_layer))\n",
    "            ensure_batch_files_exist(cur_model_name, cur_layer, pickle_dir, batch_size=batch_size_to_use, full_size=full_size_to_use)\n",
    "            cur_layer_acts = load_layer_activations_from_batch_files(cur_model_name, cur_layer, pickle_dir, batch_size=batch_size_to_use, full_size=full_size_to_use, verbose= False)\n",
    "            print('Loaded Shape is ' + str(np.shape(cur_layer_acts)))\n",
    "\n",
    "            \n",
    "print('\\n\\n*************Done with everything in this cell!*********')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Here we scatter bottleneck activations predicted from a linear fit of the image against actual activations (Figure 3B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "all_model_names = create_model_name_list(bottleneck_width_list=[1], instance_list=[1], brain_layers_list=[0, 4])\n",
    "\n",
    "for model_name in all_model_names:\n",
    "    layer_num = 3;\n",
    "    cur_return_dict = my_lin_fit_dict[(model_name,layer_num)] #Layer is 4\n",
    "    \n",
    "    plt.clf()\n",
    "    plt.figure(figsize=(8,3))    \n",
    "    max_of_each = 1\n",
    "    min_of_each = -.5\n",
    "\n",
    "#    max_of_each = np.max([np.max(y_real), np.max(y_fit)])\n",
    "#    min_of_each = np.min([np.min(y_real), np.min(y_fit)])\n",
    "    \n",
    "#    plt.plot([min_of_each, max_of_each], [min_of_each, max_of_each], '--r')\n",
    "    \n",
    "    (y_real, y_fit) =  cur_return_dict['Y_real_vs_fit'];\n",
    "    scatter_scaling = 1.5;\n",
    "    if(np.ndim(y_real)>1):\n",
    "        for chan in range(np.shape(y_real)[1]):\n",
    "            cur_y_real = y_real[:, chan];\n",
    "            cur_y_fit = y_fit[:, chan];        \n",
    "#            plt.scatter(scatter_scaling * cur_y_fit/np.max(cur_y_real), scatter_scaling * cur_y_real/np.max(cur_y_real), c = 'k', marker='.', alpha=1, s = 10)\n",
    "\n",
    "            plt.scatter(scatter_scaling * cur_y_fit/np.max(cur_y_real), scatter_scaling * cur_y_real/np.max(cur_y_real), c = 'k', marker='.', alpha=.03, s = 60)\n",
    "    else:\n",
    "            plt.scatter(scatter_scaling * y_fit/np.max(y_real), scatter_scaling *  y_real/np.max(y_real), c = 'k', marker='.', alpha=.03, s = 60)\n",
    "#            plt.scatter(scatter_scaling * cur_y_fit/np.max(cur_y_real), scatter_scaling * cur_y_real/np.max(cur_y_real), c = 'k', marker='.', alpha=1, s = 60)\n",
    "    \n",
    "\n",
    "#    plt.xlabel('Predicted Activity')\n",
    "#    plt.ylabel('Activity')\n",
    "    plt.xlim([min_of_each, max_of_each])\n",
    "    plt.ylim([-.1, max_of_each])\n",
    "    plt.xticks([-.5, 0, .5, 1])\n",
    "    plt.yticks([0, .5, 1])\n",
    "    \n",
    "#    plt.title(cur_return_dict['Notes'])\n",
    "    print(model_name)\n",
    "    output_path = 'PlotOutputs/' + model_name + 'Layer' + str(layer_num) + '.png'\n",
    "    ensure_dir(output_path)\n",
    "    plt.savefig(output_path)\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize bottleneck activations\n",
    "\n",
    "\n",
    "#### When the bottleneck is a single channel, it's nice to visualize it as an image and see how it varies with network architecture. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "should_do_full_matrix = False\n",
    "\n",
    "model_pair_list = [];\n",
    "#model_pair_list.append(['nobottleneck_1', 'nobottleneck_2'])\n",
    "crop_amount = 2800; #can be 2400 when I don't store pandas objects\n",
    "full_size_to_use = 2800;\n",
    "batch_size_to_use = 200;\n",
    "\n",
    "\n",
    "my_varexp_matr_dict = dict();\n",
    "\n",
    "\n",
    "batch_size_to_use = 200;\n",
    "full_size_to_use= 10000; \n",
    "ims_to_make = 30; \n",
    "var_exp_1_list = [];\n",
    "var_exp_2_list = [];\n",
    "fft_var_exp_1_list = []\n",
    "fft_var_exp_2_list = [];\n",
    "\n",
    "all_model_names = create_model_name_list([1], range(5), [1])\n",
    "\n",
    "mega_im_bottleneck_dict = dict();\n",
    "\n",
    "for (imodel_name, model_name) in enumerate(all_model_names):\n",
    "    print(model_name)\n",
    "    if(model_name.find('bnC_1_')>=0):\n",
    "        image_act = load_layer_activations_from_batch_files(model_name, 0, pickle_dir, batch_size=batch_size_to_use, full_size=full_size_to_use, verbose= False)\n",
    "        bottleneck_act = load_layer_activations_from_batch_files(model_name, 3, pickle_dir, batch_size=batch_size_to_use, full_size=full_size_to_use, verbose= False)\n",
    "        (fft_act1_exp, fft_act1_var, fft_act2_exp, fft_act2_var) = dft_ccas.fourier_var_exp(image_act, bottleneck_act); \n",
    "        \n",
    "        reshaped_im_act = image_act.reshape((full_size_to_use, 1024))\n",
    "        reshaped_bn_act = bottleneck_act.reshape((full_size_to_use, 1024))\n",
    "        (act1_exp, act1_var, act2_exp, act2_var) = cca_core.frac_variance_explained(reshaped_im_act.T, reshaped_bn_act.T); \n",
    "        \n",
    "        var_exp_1_list.append(act1_exp/act1_var)\n",
    "        fft_var_exp_1_list.append(fft_act1_exp/fft_act1_var)\n",
    "        var_exp_2_list.append(act2_exp/act2_var)\n",
    "        fft_var_exp_2_list.append(fft_act2_exp/fft_act2_var)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        for i_image in range(ims_to_make):\n",
    "            cur_image = image_act[i_image, ::].reshape((32,32))\n",
    "            cur_act = bottleneck_act[i_image, ::].reshape((32,32))\n",
    "            cur_image = cur_image/np.max(cur_image);\n",
    "            cur_act = cur_act/np.max(cur_act)\n",
    "            cat_im = np.concatenate([cur_image, cur_act], axis = 1)\n",
    "            cat_im_path = 'BottleneckVisualizations/' + model_name + '/Im' + str(i_image) + '.png' \n",
    "            ensure_dir(cat_im_path)\n",
    "            plt.imsave(cat_im_path, cat_im, cmap = 'gray')\n",
    "            mega_im_bottleneck_dict[(i_image, 0)] = cur_image;\n",
    "            mega_im_bottleneck_dict[(i_image, 5-imodel_name)] = cur_act;\n",
    "            \n",
    "\n",
    "vert_cat_im_list = []\n",
    "for i_image in range(ims_to_make):\n",
    "    cat_im_list = []\n",
    "    for i_grid in range(6):\n",
    "        cat_im_list.append(mega_im_bottleneck_dict[(i_image, i_grid)])\n",
    "    cat_im = np.concatenate(cat_im_list, axis = 0)\n",
    "    plt.imshow(cat_im)\n",
    "    plt.show()\n",
    "    vert_cat_im_list.append(cat_im)\n",
    "vert_cat_im = np.concatenate(vert_cat_im_list, axis = 1)\n",
    "vert_cat_im_path = 'BottleneckVisualizations/' + 'VertCat.png' \n",
    "plt.imsave(vert_cat_im_path, vert_cat_im, cmap = 'gray')\n",
    "\n",
    "            \n",
    "            \n",
    "print('Finished!')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "default_view": {},
   "name": "3_regularization.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
